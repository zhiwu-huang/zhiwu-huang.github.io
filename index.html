<!DOCTYPE html>
<html>
  <head>
    <!-- (July 2021) <title>Zhiwu Huang, Computer Vision Lab, ETH Zurich</title> -->
	  
    <!--<title>Zhiwu Huang, Assistant Professor, SMU Singapore</title>-->
    <title>Zhiwu Huang, Lecturer (Assistant Professor), University of Southampton</title>	  
	  
    <link href='https://fonts.googleapis.com/css?family=Vollkorn' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-109828585-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-109828585-1');
	</script>
	  
	<script type="text/javascript">
	   function visibility_on(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'none')
		    e.style.display = 'block';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'none')
		    e.style.display = 'block';
	   }
	   function visibility_off(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'block')
		    e.style.display = 'none';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'block')
		    e.style.display = 'none';
	   }
	   function toggle_visibility(id) {
	       var e = document.getElementById(id+"_text");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	       var e = document.getElementById(id+"_img");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	   }
	   function toggle_vis(id) {
	       var e = document.getElementById(id);
	       if (e.style.display == 'none')
		   e.style.display = 'inline';
	       else
		   e.style.display = 'none';
	   }
	</script>
	  
	  
	  
    <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      h4 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      float: left;
      height: 12em;
      margin-right: 1em;
      margin-bottom: 3em;
      }
	    
      img1 {
      float: left;
      height: 10em;
      margin-right: 1em;
      margin-bottom: 3em;
      }

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#000066}
        a:link {color:#000066}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#000066
        }
      .container {
	  display:flex;
	  justify-content:space-between;
	  align-items:center; 
      }

    </style>
  </head>
  
  <body>
    <table cellspacing="0"><tr><td width=100%>
    <!--<h1>Zhiwu Huang </h1>-->
	    
  <div class="container">	    
    <h1>Zhiwu Huang</h1>
    <div>
      <a href="index.html">Home</a> |
      <a href="research.html">Projects</a> |
      <a href="people.html">People</a> |
      <a href="publication.html">Publications</a> |
      <a href="dataset.html">Datasets</a> |
      <a href="workshop.html">Workshops</a> |
      <a href="talk.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="position.html">Openings</a> | 
      <a href="about.html">About me</a> | 
      <a href="contact.html">Contact</a>
    </div>
    <!--<nav id="navbar"> 
      <ul>
        <li><a href="index.html#Projects">Research</a></li>
        <li><a href="publication.html">Publications</a></li>
        <li><a href="workshop.html">Workshops </a></li>
        <li><a href="talk.html">Talks</a></li>
	<li><a href="teaching.html">Teaching</a></li>
	<li><a href="position.html">Open positions</a></li>
	<li><a href="about.html">About me</a></li>
	<li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>-->
</div>
	    
    
	    	    
    <div class="subheading">
      <!--<img src="./Photos/ZhiwuHuang-Hawaii.jpeg"/>-->
      <!--<img src="./Photos/ZhiwuHuang-Sydney_2x-9.jpg"/>-->
      <img src="./Photos/ZhiwuHuang_Southampton_August2023.png"/>
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research interest lies in Computer Vision and Machine Learning for Automated Video Artificial Intelligence, capable of automatically learning to understand the world through videos. My research includes applications to deepfakes tracking, affective computing, and autonomous driving. <br><br>-->	
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research studies human-inspired visual intelligence to understand the world through videos, with applications to deepfakes generation & detection, perceptual quality enhancing, affective & behavioural computing, as well as scalable autonomous driving. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research studies human-inspired visual intelligence through automated machine learning, with applications to deepfakes generation & detection, perceptual quality enhancing, affective & behavioural computing, as well as scalable autonomous driving. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research team (AutoLV, Automated Learning in Vision) studies human-inspired visual intelligence through automated machine learning on data, label, feature, neuron and task. The applications include visual deepfake, affect and behavior computing. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research team (AutoLV) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. The current research focus is on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br><br> -->
    	    
      <!--I currently working on video generation, enhancement and manipulation as well as human-focussed video clustering, classification, prediction with deep manifold learning, generative distribution learning, and neural architecture learning.-->
     <!--I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021. My research team (<a href="index.html#Projects">AutoLV</a>) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. The current research focus is on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. Please follow the <a href="position.html"> instructions </a> to reach me if you are interested in joining my research group as a PhD student. <br>-->

      <!--I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021, after finishing the postdoc research with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research group (<a href="index.html#Projects">AutoLV</a>) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br><br>-->
	
      <!--I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021. My research group (<a href="index.html#Projects">AutoLV</a>) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
      <!--(August 2021)I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="index.html#Projects">AutoVL</a> group studies Automated Visual Learning that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
      <!--Before coming to Singapore, I worked as a postdoc researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. <br><br>-->
      
	    
      <!--I am an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="index.html#Projects">AutoVL</a> group studies Automated Visual Learning that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
      <!--I am working as an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="index.html#Projects">AutoVL</a> group studies Automated Visual Learning that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
    <!--I am an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="people.html">SAVG</a> (SMU Autonomous Vision Group) performs the research that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual deepfake, affective and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>	-->
	    
 <!--I am an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="people.html">SAVG</a> (SMU Autonomous Vision Group) researches autonomous visual computing that aims for making machines to learn the visual world, all by themselves. Our current research focuses on visual deepfake, affective and behavior computing through automated machine learning on data, label, feature, neuron and task. Our ultimate quest is artificial general intelligence with rational, emotional and imaginal capabilities. <br> <br> -->
      <!--I am a <a href="https://www.southampton.ac.uk/people/62bxzm/doctor-zhiwu-huang"> Lecturer (Assistant Professor) </a> in the <a href="https://www.southampton.ac.uk/research/groups/vision-learning-control"> Vision, Learning and Control (VLC) </a> group within the school of <a href="http://ecs.soton.ac.uk"> Electronics and Computer Science (ECS)</a> at the <a href="https://www.southampton.ac.uk"> University of Southampton </a>. I mainly research generative computer vision and continual machine learning for artificial general intelligence. My currently focused machine learning methodologies include generative modelling, continual learning, and language prompting. The ultimate quest of my research is to empower machines with rational, emotional and imaginal intelligence.  <br> <br> -->

      I am a <a href="https://www.southampton.ac.uk/people/62bxzm/doctor-zhiwu-huang">Lecturer (Assistant Professor)</a> affiliated with the <a href="https://www.southampton.ac.uk/research/groups/vision-learning-control">Vision, Learning, and Control (VLC)</a> group in the School of <a href="http://ecs.soton.ac.uk">Electronics and Computer Science (ECS)</a> at the <a href="https://www.southampton.ac.uk">University of Southampton</a>.  <br><br>

      I specialize in computer vision and machine learning for artificial general intelligence. My current research focuses on generative AI (GenAI) functions of generation, detection, and emotion in computers, devices, and robots, with the potential for broad impact in healthcare, art, and education. My research team has been exploring computer vision and machine learning approaches like diffusion generative modeling, geometric deep learning, and continual deep learning. Ultimately, we aim to make machines more capable and controllable, enabling them to better understand both the physical world and human beings.
	    	
      <!--My primary research is dedicated to advancing computer vision and machine learning within the context of artificial general intelligence. The overarching goal is to make machine learning (deep learning) models more capable and controllable to understand the physical world. To this end, I am interested in exploring machine learning methodologies, including generative modeling, continual learning, and affective computing. <br><br>    -->
	  
     <!--<em> I am looking for motivated and talented researchers/students to join our research group. Please have a look at the <a href="position.html"> Openings </a> and reach me if you are interested. </em> -->

      <!--<em> I am actively looking for motivated and talented PhD students to join our reaseach group at SMU (ranked No.47 in the AI category and No.85 in the CS discipline according to <a href="http://csrankings.org/#/index?all&world">CSRankings</a>). Please follow the <a href="position.html"> instructions </a> to reach me if you are interested. </em>-->

      
      <!--<b> [<a href="http://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en">Google Scholar</a>] [<a href="https://github.com/zhiwu-huang"> Github </a>] </b> -->
      
       <!-- <b>Prospective students </b>, please <a href="javascript:toggle_vis('contact')">read this</a> before contacting me.
              <div id="contact" style="display:none"> 
                  Thank you for your interest in joining my research team! I am taking on new MS and PhD students each year. However, I ask that you do not contact me directly with regard to MS or PhD admissions until after you are admitted, as I will not be able to reply to individual emails. <br>
                  If you are interested in a <i>post-doc</i> position, please read <a href="https://goo.gl/forms/aKL2gnq8T80FNVMb2">this form</a>. <br>
                  If you are a current or admitted <i>ETH MS student</i> interested in research positions, please read <a href="https://goo.gl/forms/uJuYOfIBQVPhEEDy1">this form</a>. <br>
                  If you are not an ETH student and insteresed in research positions, please read <a href="https://goo.gl/forms/9scJRH3hw6z7GNbj2">this form</a>.
              </div>
        </p>-->
        
    </div>
	    
	    
    

    <!--<nav>
      Jump to: 
      <a href="index.html#Projects">Research</a> |
      <a href="publication.html">Publications</a> |
      <a href="workshop.html">Workshops </a> |
      <a href="talk.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="position.html">Open positions</a> | 
      <a href="about.html">About me</a> | 
      <a href="contact.html">Contact</a>
    </nav>-->
	    
    <h2>News</h2>
	        <li> 02/2025, One inspiring paper <a href="https://github.com/iamwangyabin/OpenSDI">"OpenSDI: Spotting Diffusion-Generated Images in the Open World" </a> has been accepted to CVPR 2025. Huge thanks to the reviewers and the chairs! Let's <b>spot AI images, like <a href="https://www.bbc.co.uk/bitesize/articles/z6s4239"> those on social media (reported by BBC) </a>, in the open world!</b> </li>	    	    
	    	<li> 10/2023, We have openings for PhD positions: 'Generative Modeling in Computer Vision' and 'Deepfake Detection with Continual Learning'. Note that these positions are open to students from UK and Horizon Europe qualifying countries (meeting the criteria for UK home-level fees) as well as other international students.  </b>
	        <li> 02/2023, <b> We are opening some <a href="position.html"> positions </a> for talents </b> who are keen to publish papers, open source code, and make an impact. </li>
	        <li> 02/2023, One interesting paper <a href="https://arxiv.org/abs/2303.14412"> "Freestyle Layout-to-Image Synthesis" </a> is accepted as a <b>highlight</b> (10% of accepted papers, 2.5% of submissions) to CVPR 2023. This paper introduces <b> freestyle layout-to-image synthesis with diffusion generative network (<a href='https://github.com/essunny310/FreestyleNet'>FreestyleNet</a>)</b>. The proposed FreestyleNet produces realistic-looking and creative images like ‘a warehouse running on a railroad’ and 'a hornless unicorn sitting on a bench'. Thanks all the reviewers for valuable comments and constructive suggestions! </li>	    	    
	    	<li> 01/2023, I join University of Southampton as a <a href="https://www.southampton.ac.uk/people/62bxzm/doctor-zhiwu-huang">Lecturer (Assistant Professor)</a> in Computer Science. </li>	    	    
	    	<li> 11/2022, One paper <a href="https://arxiv.org/pdf/2012.13033.pdf"> "An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement" </a> gets accepted to IJCV.
	        <li> 11/2022, Two papers "Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference" and "Riemannian Local Mechanism for SPD Neural Networks" are accepted at AAAI 2023. </li>
	    	<li> 10/2022, One paper <a href="https://arxiv.org/pdf/2204.05576.pdf"> "Multi-agent Actor-Critic with Time Dynamical Opponent Model" </a> gets accepted to Neurocomputing. </li>	    	    
	        <li> 09/2022, One inspiring paper <a href="https://openreview.net/pdf?id=ZVe_WeMold"> "S-Prompts Learning with Pre-trained Transformers: An Occam's Razor for Domain Incremental Learning" </a> gets accepted to NeurIPS 2022. This paper proposes <b>a rule-breaking continual learning paradigm (<a href='https://github.com/iamwangyabin/S-Prompts'>S-Prompts</a>)</b>. It does not require the accumulation of the knowledge from previously learned domains. Instead, it merely learns the knowledge independently domain by domain, through simply prompting the state-of-the-art transformers. </li>	    	    
                <li> 08/2022, One paper <a href="https://arxiv.org/pdf/2205.05467.pdf"> "A Continual Deepfake Detection Benchmark: Dataset, Methods, and Essentials" </a> gets accepted to WACV 2023. </li>	    	    
	        <li> 06/2022, One paper <a href="https://arxiv.org/pdf/2106.03959.pdf"> "Trilevel Neural Architecture Search for Efficient Single Image Super-Resolution" </a> is accepted by the CVPR-2022 NAS workshop. </li>	    	    
	        <li> 03/2022, One paper <a href="https://arxiv.org/pdf/2106.03959.pdf"> "Generative Flows with Invertible Attentions" </a> is accepted by CVPR 2022, with surprisingly increased final review scores (2 strong accepts and 2 borderline accepts). Thanks all the reviewers for the valuable comments and suggestions! This paper introduces an interesting idea of <b> Invertible Transformer-based Attentions </b> to Generative Normalizing Flows. </li>	    	    
	    	<li> 10/2021, One paper <a href="https://arxiv.org/pdf/2110.05621.pdf"> "Neural Architecture Search for Efficient Uncalibrated Deep Photometric Stereo" </a> is accepted by WACV 2022. </li>	    	    
	        <li> 09/2021, I join SMU Singapore as a tenure-track Assistant Professor in Computer Science. </li>	
	    
	        <li> <a href="javascript:toggle_vis('news')"> more news...</a> </li>
		<div id="news" style="display:none">
			<li> 07/2021, One paper <a href="https://arxiv.org/pdf/2104.04282.pdf"> "Direct Differentiable Augmentation Search" </a> is accepted by ICCV 2021. </li>	    	    
			<li> 04/2021, One paper <a href="https://arxiv.org/pdf/2010.14535.pdf"> "Neural Architecture Search of SPD Manifold Networks" </a> is accepted by IJCAI 2021. </li>	    	    
			<li> 03/2021, Two papers <a href="https://arxiv.org/pdf/2102.06696.pdf"> "Efficient Conditional GAN Transfer with Knowledge Propagation across Classes" </a> and <a href="./Papers/GANmut_CVPR2021.pdf">"GANmut: Learning Interpretable Conditional Space for Gamut of Emotions" </a> are accepted by CVPR 2021. </li>	    	    
			<li> 01/2021, One paper <a href="https://arxiv.org/pdf/2103.04217.pdf"> "Spectral Tensor Train Parameterization of Deep Learning Layers" </a> is accepted by AISTATS 2021. </li>	    	    
			<li> 12/2020, One paper <a href="https://arxiv.org/pdf/2007.16112.pdf"> "Neural Architecture Search as Sparse Supernet" </a> is accepted by AAAI 2021. </li>	    	    
			<li> 11/2020, One paper <a href="https://arxiv.org/pdf/2010.09849.pdf"> "Facial Emotion Recognition with Noisy Multi-task Annotations" </a> is accepted by WACV 2021. </li>
			<li> 08/2020, One paper <a href="./Papers/ECCV_2020__AIM2020_VXSR.pdf"> "AIM 2020 Challenge on Video Extreme Super-Resolution: Methods and Results" </a> will appear at the workshop AIM in conjunction with ECCV 2020. </li>
			<li> 07/2020, One paper <a href="./Papers/BMVC2020_WeaklyPaired.pdf"> "Weakly Paired Multi-Domain Image Translation" </a> is accepted by BMVC 2020 as an oral. </li>
			<li> 07/2020, One paper <a href= "https://arxiv.org/pdf/2007.09180.pdf"> "Off-Policy Reinforcement Learning for Efficient and Effective GAN Architecture Search" </a> is accepted by ECCV 2020. </li>
			<li> 05/2020, We are organizing <a href= "https://competitions.codalab.org/competitions/24685"> AIM Video Super-Resolution Challenge </a> @ECCV 2020. </li>
			<li> 05/2020, One paper <a href="https://arxiv.org/pdf/2005.02291.pdf">"NTIRE 2020 Challenge on Video Quality Mapping: Methods and Results" </a> will appear at the workshop NTIRE in conjunction with CVPR 2020. </li>
			<li> 12/2019, We are organizing <a href= "https://competitions.codalab.org/competitions/20247"> NTIRE Video Quality Mapping Challenge </a> @CVPR 2020. </li>
			<li> 10/2019, One dataset paper <a href="http://www.vision.ee.ethz.ch/~timofter/publications/Kim-ICCVW-2019.pdf"> "The Vid3oC and IntVID Datasets for Video Super Resolution and Quality Mapping" </a> will appear at the workshop AIM in ICCV 2019. </li>
			<li>10/2019, We are organizing a workshop <a href= "http://www.vision.ee.ethz.ch/aim19/"> "AIM: Advances in Image Manipulation Workshop and Challenges on Image and Video Manipulation" </a>
	  and a tutorial <a href= "http://www.vision.ee.ethz.ch/fire19/index_fire19.html"> "FIRE: From Image Restoration to Enhancement and Beyond" </a> at ICCV, Oct. 27, 2019. </li>

			<li>02/2019, One paper <a href="https://arxiv.org/pdf/1706.02631.pdf">"Sliced Wasserstein Generative Models" </a> is accepted by CVPR 2019. This paper was selected as one of the <b> best publications </b> of the week (20.04.2019), by DeepAI. <a  href="https://deepai.org/publication/sliced-wasserstein-generative-models"> Link to DeepAI Website </a> </li>


			<li>11/2018, One paper "Manifold-valued Image Generation with Wasserstein Generative Adversarial Nets" is accepted by AAAI 2019. <em> This paper applies the theory of optimal transport on non-compact manifolds from Alessio Figalli (2018 Fields Medal winner) to generative modeling, which is able to generate photo-realistic biological samples. </em> </li>
			<!--<b> The paper applies the theory of optimal transport on non-compact manifolds from Alessio Figalli, who won 2018 Fields Medal. </b> -->
			<li>07/2018, One paper "Wasserstein Divergence for GANs" is accepted by ECCV 2018.</li>
			<li>04/2018, One paper "Covariance Pooling for Facial Expression Recognition" is accepted by the workshop DiffCVML in CVPR 2018.</li>
			<li>11/2017, One paper "Cross Euclidean-to-Riemannian Metric Learning with Application to Face Recognition from Video" is accepted as a Regular Paper in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</li>
			<li>11/2017, One paper "Building Deep Networks on Grassmann Manifolds" (GrNet) is accepted by AAAI 2018.</li>
			<li>08/2017, One paper "Discriminant Analysis on Riemannian Manifold of Gaussian Distributions for Face Recognition with Image Sets" is accepted by IEEE Transactions on Image Processing (TIP).</li>
			<li>07/2017, One paper "Geometry-aware Similarity Learning on SPD Manifolds for Visual Recognition" is accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT).</li>
			<li>02/2017, One paper "Deep Learning on Lie Groups for Skeleton-based Action Recognition" (LieNet) is accepted as a spotlight by CVPR 2017. <em> This paper proposes deep networks of Lie Groups for skeleton-based action recognition. </em> </li>
			<li>11/2016, One paper "A Riemannian Network for SPD Matrix Learning" (SPDNet) is accepted by AAAI 2017. <em>  This paper opens a new direction of deep manifold networks. </em> </li>
			 <li>09/2015, I join ETH Zurich as a Postdoc Researcher in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>. </li>

	      </div>	

          </td>
    </tr></table>
    
   
	    
   </body>
</html>
