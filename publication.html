<!DOCTYPE html>
<html>
  <head>
    <!-- (July 2021) <title>Zhiwu Huang, Computer Vision Lab, ETH Zurich</title> -->
	  
    <!--<title>Zhiwu Huang, Assistant Professor, SMU Singapore</title>-->
    <title>Zhiwu Huang, Lecturer (Assistant Professor), University of Southampton</title>	  
	  
    <link href='https://fonts.googleapis.com/css?family=Vollkorn' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-109828585-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-109828585-1');
	</script>
	  
	<script type="text/javascript">
	   function visibility_on(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'none')
		    e.style.display = 'block';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'none')
		    e.style.display = 'block';
	   }
	   function visibility_off(id) {
		var e = document.getElementById(id+"_text");
		if(e.style.display == 'block')
		    e.style.display = 'none';
		var e = document.getElementById(id+"_img");
		if(e.style.display == 'block')
		    e.style.display = 'none';
	   }
	   function toggle_visibility(id) {
	       var e = document.getElementById(id+"_text");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	       var e = document.getElementById(id+"_img");
	       if(e.style.display == 'inline')
		  e.style.display = 'block';
	       else
		  e.style.display = 'inline';
	   }
	   function toggle_vis(id) {
	       var e = document.getElementById(id);
	       if (e.style.display == 'none')
		   e.style.display = 'inline';
	       else
		   e.style.display = 'none';
	   }
	</script>
	  
	  
	  
    <style>
      body {
      font-family: 'Vollkorn', sans-serif;
      }

      .subheading {
      font-size: 120%;
      }

      h2 {
      clear: left;
      margin-top: 1em;
      }
      
      h3 {
      clear: left;
      margin-top: 1em;
      }
      
      img {
      float: left;
      height: 12em;
      margin-right: 1em;
      margin-bottom: 3em;
      }
     

      p {
      margin: 0.5em;
      }

      nav {
      margin-top: 3em;
      margin-bottom: 1em;
      }
        
        a:visited {color:#000066}
        a:link {color:#000066}
        a:hover {color: #FF0000}
        
        h1,h2,h3{
            color:#000066
        }
	    
      .container {
	  display:flex;
	  justify-content:space-between;
	  align-items:center; 
      }

    </style>
  </head>
  
  <body>
    <table cellspacing="0"><tr><td width=100%>
    <!--<h1>Zhiwu Huang </h1>-->
	    
  <div class="container">	    
    <h1>Zhiwu Huang</h1>
    <div>
      <a href="index.html">Home</a> |
      <a href="research.html">Projects</a> |
      <a href="people.html">People</a> |
      <a href="publication.html">Publications</a> |
      <a href="dataset.html">Datasets</a> |
      <a href="workshop.html">Workshops</a> |
      <a href="talk.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="position.html">Openings</a> | 
      <a href="about.html">About me</a> | 
      <a href="contact.html">Contact</a>
    </div>
    <!--<nav id="navbar"> 
      <ul>
        <li><a href="index.html#Projects">Research</a></li>
        <li><a href="publication.html">Publications</a></li>
        <li><a href="workshop.html">Workshops </a></li>
        <li><a href="talk.html">Talks</a></li>
	<li><a href="teaching.html">Teaching</a></li>
	<li><a href="position.html">Open positions</a></li>
	<li><a href="about.html">About me</a></li>
	<li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>-->
</div>
	    
    
	    	    
    <div class="subheading">
      <!--<img src="./Photos/ZhiwuHuang-Hawaii.jpeg"/>-->
      <img src="./Photos/ZhiwuHuang-Sydney_2x-9.jpg"/>
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research interest lies in Computer Vision and Machine Learning for Automated Video Artificial Intelligence, capable of automatically learning to understand the world through videos. My research includes applications to deepfakes tracking, affective computing, and autonomous driving. <br><br>-->	
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research studies human-inspired visual intelligence to understand the world through videos, with applications to deepfakes generation & detection, perceptual quality enhancing, affective & behavioural computing, as well as scalable autonomous driving. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research studies human-inspired visual intelligence through automated machine learning, with applications to deepfakes generation & detection, perceptual quality enhancing, affective & behavioural computing, as well as scalable autonomous driving. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research team (AutoLV, Automated Learning in Vision) studies human-inspired visual intelligence through automated machine learning on data, label, feature, neuron and task. The applications include visual deepfake, affect and behavior computing. <br><br>-->
      <!--I am a postdoctoral researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research team (AutoLV) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. The current research focus is on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br><br> -->
    	    
      <!--I currently working on video generation, enhancement and manipulation as well as human-focussed video clustering, classification, prediction with deep manifold learning, generative distribution learning, and neural architecture learning.-->
     <!--I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021. My research team (<a href="index.html#Projects">AutoLV</a>) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. The current research focus is on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. Please follow the <a href="position.html"> instructions </a> to reach me if you are interested in joining my research group as a PhD student. <br>-->

      <!--I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021, after finishing the postdoc research with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html"> ETH Zurich </a>. My research group (<a href="index.html#Projects">AutoLV</a>) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br><br>-->
	
      <!--I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg"> School of Computing and Information Systems <a> at <a href="https://www.smu.edu.sg"> Singapore Management University (SMU) </a> in Summer of 2021. My research group (<a href="index.html#Projects">AutoLV</a>) studies automated learning in vision that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
      <!--(August 2021)I will be starting as an Assistant Professor in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="index.html#Projects">AutoVL</a> group studies Automated Visual Learning that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
      <!--Before coming to Singapore, I worked as a postdoc researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. <br><br>-->
      
	    
      <!--I am an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="index.html#Projects">AutoVL</a> group studies Automated Visual Learning that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
      <!--I am working as an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="index.html#Projects">AutoVL</a> group studies Automated Visual Learning that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual fake, affect and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>-->
	    
    <!--I am an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="people.html">SAVG</a> (SMU Autonomous Vision Group) performs the research that aims for making machines to learn the visual world, all by themselves. Our research focuses on visual deepfake, affective and behavior computing through automated machine learning on data, label, feature, neuron and task. <br> <br>	-->
	    
 <!--I am an Assistant Professor of Computer Science in the <a href="https://sis.smu.edu.sg">School of Computing and Information Systems<a> at <a href="https://www.smu.edu.sg">Singapore Management University (SMU)</a>. Before coming to Singapore, I worked as a Guest/Postdoc Researcher with Prof. <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjQ4LC0xOTcxNDY1MTc4.html">Luc Van Gool</a> in <a href="http://www.vision.ee.ethz.ch/">Computer Vision Lab</a> at <a href="https://ethz.ch/en.html">ETH Zurich</a>. My <a href="people.html">SAVG</a> (SMU Autonomous Vision Group) researches autonomous visual computing that aims for making machines to learn the visual world, all by themselves. Our current research focuses on visual deepfake, affective and behavior computing through automated machine learning on data, label, feature, neuron and task. Our ultimate quest is artificial general intelligence with rational, emotional and imaginal capabilities. <br> <br> -->
      <!--I am a <a href="https://www.southampton.ac.uk/people/62bxzm/doctor-zhiwu-huang"> Lecturer (Assistant Professor) </a> in the <a href="https://www.southampton.ac.uk/research/groups/vision-learning-control"> Vision, Learning and Control (VLC) </a> group within the school of <a href="http://ecs.soton.ac.uk"> Electronics and Computer Science (ECS)</a> at the <a href="https://www.southampton.ac.uk"> University of Southampton </a>. I mainly research generative computer vision and continual machine learning for artificial general intelligence. My currently focused machine learning methodologies include generative modelling, continual learning, and language prompting. The ultimate quest of my research is to empower machines with rational, emotional and imaginal intelligence.  <br> <br> -->

 I am a <a href="https://www.southampton.ac.uk/people/62bxzm/doctor-zhiwu-huang">Lecturer (Assistant Professor)</a> affiliated with the <a href="https://www.southampton.ac.uk/research/groups/vision-learning-control">Vision, Learning, and Control (VLC)</a> group in the School of <a href="http://ecs.soton.ac.uk">Electronics and Computer Science (ECS)</a> at the <a href="https://www.southampton.ac.uk">University of Southampton</a>.  <br><br>

        I specialize in computer vision and machine learning for artificial general intelligence. I am committed to teaching AI/machines/robots to comprehend the world through multimodal data, enabling them to achieve animal-level, or human-level, or superhuman-level general intelligence. My current focus is on making machine learning models more capable and controllable to understand the physical world, through scaling and aligning compute, data, models, and tasks for deep learning. I am interested in exploring machine learning methodologies, including generative modeling, continual learning, and affective computing.
	    	
      <!--My primary research is dedicated to advancing computer vision and machine learning within the context of artificial general intelligence. The overarching goal is to make machine learning (deep learning) models more capable and controllable to understand the physical world. To this end, I am interested in exploring machine learning methodologies, including generative modeling, continual learning, and affective computing. <br><br>    -->
	  
     <!--<em> I am looking for motivated and talented researchers/students to join our research group. Please have a look at the <a href="position.html"> Openings </a> and reach me if you are interested. </em> -->

      <!--<em> I am actively looking for motivated and talented PhD students to join our reaseach group at SMU (ranked No.47 in the AI category and No.85 in the CS discipline according to <a href="http://csrankings.org/#/index?all&world">CSRankings</a>). Please follow the <a href="position.html"> instructions </a> to reach me if you are interested. </em>-->

      
      <!--<b> [<a href="http://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en">Google Scholar</a>] [<a href="https://github.com/zhiwu-huang"> Github </a>] </b> -->
      
       <!-- <b>Prospective students </b>, please <a href="javascript:toggle_vis('contact')">read this</a> before contacting me.
              <div id="contact" style="display:none"> 
                  Thank you for your interest in joining my research team! I am taking on new MS and PhD students each year. However, I ask that you do not contact me directly with regard to MS or PhD admissions until after you are admitted, as I will not be able to reply to individual emails. <br>
                  If you are interested in a <i>post-doc</i> position, please read <a href="https://goo.gl/forms/aKL2gnq8T80FNVMb2">this form</a>. <br>
                  If you are a current or admitted <i>ETH MS student</i> interested in research positions, please read <a href="https://goo.gl/forms/uJuYOfIBQVPhEEDy1">this form</a>. <br>
                  If you are not an ETH student and insteresed in research positions, please read <a href="https://goo.gl/forms/9scJRH3hw6z7GNbj2">this form</a>.
              </div>
        </p>-->
        
    </div>
    

    <!--<nav>
      Jump to: 
      <a href="index.html#Projects">Research</a> |
      <a href="publication.html">Publications</a> |
      <a href="workshop.html">Workshops </a> |
      <a href="talk.html">Talks</a> |
      <a href="teaching.html">Teaching</a> |
      <a href="position.html">Open positions</a> | 
      <a href="about.html">About me</a> | 
      <a href="contact.html">Contact</a>
    </nav>-->
      
    <!--<h2>Publications</h2>-->

      <!--<h2>arXiv and Tech Reports</h2>-->	            

      <h2>Selected Publication</h2>
	
      <p> Han Xue, <b>Zhiwu Huang</b>, Qianru Sun, Li Song, Wenjun Zhang. Freestyle Layout-to-Image Synthesis. Accepted as a <b>highlight</b> (10% of accepted papers, 2.5% of submissions). In <em> Computer Vision and Pattern Recognition (CVPR), 2023. </em>  <a href="https://arxiv.org/pdf/2303.14412.pdf">Preprint </a> | <a href="https://essunny310.github.io/FreestyleNet/">Project Page</a> | <a href="https://github.com/essunny310/FreestyleNet"> Code </a> | <a href="https://www.youtube.com/watch?v=EUeV3b3XHe8"> Oral Presentation </a>   </p>
      
      <p> Yabin Wang*, Zhiheng Ma*, <b>Zhiwu Huang</b>, Yaowei Wang, Zhou Su, Xiaopeng Hong. <em> (*indicates equal contribution) </em>. Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference. In <em> Association for the Advancement of Artificial Intelligence (AAAI) </em>, 2023. <a href="https://arxiv.org/pdf/2211.15969.pdf"> Preprint </a> | <a href="https://github.com/iamwangyabin/ESN"> Code </a> </p> 

    
      <p> Dario Fuoli, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool, Radu Timofte. An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement. <em>International Journal of Computer Vision (IJCV)</em>, 2022.  <a href="https://arxiv.org/abs/2012.13033">Preprint</a> </p> <!--<b> (Automated Data Learning for Deepfake Computing) </b> -->
      
      <p> Yuan Tian, Klaus-Rudolf Kladny, Qin Wang, <b>Zhiwu Huang</b>, Olga Fink. Multi-agent Actor-Critic with Time Dynamical Opponent Model. <em>Neurocomputing</em>, 2022. <a href="https://www.sciencedirect.com/science/article/pii/S0925231222013200"> Paper </a> | <a href="https://github.com/Yuantian013/TDOM-AC"> Code </a> </p> 
   
      <p> Yabin Wang,  <b>Zhiwu Huang*</b>, Xiaopeng Hong*. <em> (*indicates corresponding author) </em>. S-Prompts Learning with Pre-trained Transformers: An Occam's Razor for Domain Incremental Learning. In <em> Conference on Neural Information Processing Systems (NeurIPS) </em>, 2022. <a href="https://openreview.net/pdf?id=ZVe_WeMold"> Paper</a> | <a href="https://openreview.net/forum?id=ZVe_WeMold"> OpenReview </a> | <a href="https://www.youtube.com/watch?v=MkXa3xD0lRM">Presentation@ContinualAI</a> | <a href="https://github.com/iamwangyabin/S-Prompts"> Code </a> </p> 
	    
      <p> Chuqiao Li, <b>Zhiwu Huang*</b>, Danda Pani Paudel, Yabin Wang, Mohamad Shahbazi, Xiaopeng Hong, Luc Van Gool. <em> (*indicates corresponding author) </em>. A Continual Deepfake Detection Benchmark: Dataset, Methods, and Essentials. In <em> Winter Conference on Applications of Computer Vision (WACV) </em>, 2023. <a href="https://arxiv.org/abs/2205.05467"> Preprint </a> | <a href="https://coral79.github.io/CDDB_web/"> Project Page </a> | <a href="./Videos/CDDB_WACV2023_compressed.mp4"> Oral Presentation </a> </p>
	    
      <p> Yan Wu, <b>Zhiwu Huang</b>, Suryansh Kumar, Rhea Sanjay Sukthanker, Radu Timofte, Luc Van Gool. Trilevel Neural Architecture Search for Efficient Single Image Super-Resolution. In <em> Computer Vision and Pattern Recognition (CVPR) NAS workshop </em>, 2022. <a href="./Papers/TrilevelNAS_main_CVPR2022NAS.pdf"> Extended Abstract Paper </a> | <a href="./Papers/TrilevelNAS_supp_CVPR2022NAS.pdf"> Supplementary Material </a> | <a href="https://arxiv.org/abs/2101.06658"> Preprint </a> | <a href="./Videos/TrilevelNAS_cvpr2022nas_oral.mp4"> Oral Presentation </a> </p>
	    
      <p> Rhea Sanjay Sukthanker, <b>Zhiwu Huang</b>, Suryansh Kumar, Radu Timofte, Luc Van Gool. Generative Flows with Invertible Attentions. In <em> Computer Vision and Pattern Recognition (CVPR), 2022. </em>  <a href="https://arxiv.org/abs/arXiv:2106.03959">Preprint </a> | <https://sotonac-my.sharepoint.com/:u:/g/personal/zh1r23_soton_ac_uk/ESi_pAMO8chNv9khRmEPPycBXNs8TiAlylQc49h6C9gEPA"> Code (raw, Size:<b>32G</b> including code, data and pretrained models)</a> [On Request] </p> <!--<b> (Automated Data Learning for Deepfake Computing) </b>-->
  
      <!-- <p> Francesco Sarno, Suryansh Kumar, Berk Kaya, <b>Zhiwu Huang</b>, Vittorio Ferrari, Luc Van Gool. Neural Architecture Search for Efficient Uncalibrated Deep Photometric Stereo. In <em> Winter Conference on Applications of Computer Vision (WACV), 2022. </em> <a href="https://arxiv.org/pdf/2110.05621.pdf"> Preprint </a> </p> -->
	    
      <p> Aoming Liu, Zehao Huang, <b>Zhiwu Huang</b>, Naiyan Wang. Direct Differentiable Augmentation Search. In <em> International Conference on Computer Vision (ICCV), 2021. </em> <a href="https://arxiv.org/pdf/2104.04282.pdf">Preprint </a> | <a href="https://github.com/zxcvfd13502/DDAS_code"> Code </a> </p> <!--<b> (Automated Data Augmentation Learning for Object Classification and Detection) </b>-->

      <!-- <h2>2020</h2>-->
	    
      <p> Rhea Sanjay Sukthanker, <b>Zhiwu Huang</b>, Suryansh Kumar, Erik Goron Endsjo, Yan Wu, Luc Van Gool. Neural Architecture Search of SPD Manifold Networks. In <em> International Joint Conference on Artificial Intelligence (IJCAI), 2021 </em>. <a href="https://www.ijcai.org/proceedings/2021/0413.pdf"> Paper </a> | <a href="https://github.com/rheasukthanker/SPDNetNAS"> Code </a> | <a href="./Videos/SPDNetNAS_IJCAI21_presenation_Rhea.mp4"> Oral Presentation </a> </br>  <!--<b> (Automated Neuron Learning for Affective and Behavioral Computing) </b>-->
      <b> Extension:</b> Samuele Serafino, <b>Zhiwu Huang</b>, Suryansh Kumar, Luc Van Gool. Neural Architecture Search on Lie Groups for Skeleton-based Action Recognition. <em> Tech. Report (Semester Thesis), 2020.	</em>  <a href="./Papers/LieNetNAS_thesis_Samuele.pdf">Paper</a></p>
    
      <p> Mohamad Shahbazi, <b>Zhiwu Huang</b>, Danda Pani Paudel, Ajad Chhatkuli, Luc Van Gool. Efficient Conditional GAN Transfer with Knowledge Propagation across Classes. In <em> Computer Vision and Pattern Recognition (CVPR), 2021. </em> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Shahbazi_Efficient_Conditional_GAN_Transfer_With_Knowledge_Propagation_Across_Classes_CVPR_2021_paper.pdf"> Paper </a> | <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Shahbazi_Efficient_Conditional_GAN_CVPR_2021_supplemental.pdf"> Supp </a> | <a href="https://github.com/mshahbazi72/cGANTransfer"> Code </a> | <a href="./Videos/cGANTransfer_CVPR2021.mp4"> Oral Presentation </a>  </p> <!--<b> (Automated Task Learning for Deepfake Computing) </b> -->
	    
      <p> Stefano D'Apolito, Danda Pani Paudel, <b>Zhiwu Huang*</b>, Andres Romero Vergara, Luc Van Gool. <em> (*indicates <a href="./Papers/CVPR_GANmut_Corrspondingauthor.png"> corresponding author </a>) </em>. GANmut: Learning Interpretable Conditional Space for Gamut of Emotions. In <em> Computer Vision and Pattern Recognition (CVPR), 2021. </em> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/dApolito_GANmut_Learning_Interpretable_Conditional_Space_for_Gamut_of_Emotions_CVPR_2021_paper.pdf"> Paper </a> | <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/dApolito_GANmut_Learning_Interpretable_CVPR_2021_supplemental.zip"> Supp </a> | <a href="https://github.com/stefanodapolito/GANmut"> Code </a> | <a href="./Videos/GANmut_CVPR2021_compressed.mp4"> Oral Presentation </a> </p> <!--<b> (Automated Label Learning for Affective Computing) </b>-->

      <p> Anton Obukhov, Maxim Rakhuba, Alexander Liniger, <b>Zhiwu Huang</b>, Stamatios Georgoulis, Dengxin Dai, Luc Van Gool. Spectral Tensor Train Parameterization of Deep Learning Layers. In <em> International Conference on Artificial Intelligence and Statistics (AISTATS), 2021. </em> <a href="https://arxiv.org/pdf/2103.04217.pdf"> Preprint </a> | <a href="https://www.obukhov.ai/sttp"> Project Page </a> </p> <!--<b> (Automated Neuron Learning for Deepfake Computing) </b> -->
   
      <p> Yan Wu*, Aoming Liu*, <b>Zhiwu Huang</b>, Siwei Zhang, Luc Van Gool. <em> (*indicates equal contributions) </em>. Neural Architecture Search as Sparse Supernet. In <em> Association for the Advancement of Artificial Intelligence (AAAI), 2021 </em>. <a href="https://arxiv.org/pdf/2007.16112.pdf"> Preprint </a> | <a href="./Videos/sparsenas_aaai2021_short.mp4"> Oral Presentation (short) </a> | <a href="https://data.vision.ee.ethz.ch/zzhiwu/sparsenas-master3_Final_Model.zip">Code (raw)</a> </p>  <!--<b> (Automated Neuron Learning for Object Classification) </b>-->

      <p> Siwei Zhang, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Facial Emotion Recognition with Noisy Multi-task Annotations. In <em> Winter Conference on Applications of Computer Vision (WACV), 2021 </em>.  <a href="https://arxiv.org/pdf/2010.09849.pdf"> Preprint </a> | <a href="https://github.com/sanweiliti/noisyFER"> Code </a> | <a href="./Videos/noisyFER_WACV2021.mp4"> Oral Presentation </a> </p> <!--<b> (Automated Label Learning for Affective Computing) </b>-->
	    
      <p> Dario Fuoli, <b>Zhiwu Huang</b>, Radu Timofte and et al.  AIM 2020 Challenge on Video Extreme Super-Resolution: Methods and Results. In <em> European Conference on Computer Vision (ECCV) workshop, 2020 </em>. <a href="./Papers/ECCV_2020__AIM2020_VXSR.pdf">Paper </a> | <a href="./Videos//aim2020vxsr.mp4"> Oral Presentation </a> | <a href="https://competitions.codalab.org/competitions/24685"> Challenge Entry </a> </p>
    
      <!-- <p> Marc Yanlong Zhang, <b>Zhiwu Huang</b>, Danda Pani Paudel, Janine Thoma, Luc Van Gool. Weakly Paired Multi-Domain Image Translation. In <em> British Machine Vision Conference (BMVC), 2020. (Oral). </em> <a href="./Papers//BMVC2020_WeaklyPaired.pdf"> Paper </a> | <a href="./Papers//BMVC2020_WeaklyPaired_suppl.pdf"> Supp </a> | <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0841.html"> Oral Presentation </a>  | <a href="https://data.vision.ee.ethz.ch/zzhiwu/WeaklyPairedTrans_BMVC20.zip">Code (raw)</a> | <a href="https://data.vision.ee.ethz.ch/zzhiwu/WeaklySupervisedRobotcar.zip">Data (raw)</a> -->
	      
      <p> Yuan Tian*, Qin Wang*, <b>Zhiwu Huang</b>, Wen Li, Dengxin Dai, Minghao Yang, Jun Wang, Olga Fink. <em> (*indicates equal contributions) </em>. Off-Policy Reinforcement Learning for Efficient and Effective GAN Architecture Search. In <em> European Conference on Computer Vision (ECCV), 2020 </em>. <a href="https://arxiv.org/pdf/2007.09180.pdf"> Paper </a> | <a href="https://github.com/Yuantian013/E2GAN"> Code </a> | <a href="https://youtu.be/0iBHFzs9sgY"> Oral Presentation </a>  </p> <!--<b> (Automated Neuron Learning for Deepfake Computing) </b> -->
 
      <p> Dario Fuoli, <b>Zhiwu Huang</b>, Martin Danelljan, Radu Timofte and et al. NTIRE 2020 Challenge on Video Quality Mapping: Methods and Results. In <em> Computer Vision and Pattern Recognition (CVPR) workshop, 2020. </em> <a href="https://arxiv.org/pdf/2005.02291.pdf">Paper</a> | <a href="./Talks/NTIRE2020ChallengeVideoQualityMapping_20200615.pdf"> Slides </a> | <a href="https://competitions.codalab.org/competitions/20247"> Challenge Entry </a> </p>
      

      <!-- <h2>2019</h2>-->
      
      <!-- <p> Sohyeong Kim, Guanju Li, Dario Fuoli, Martin Danelljan, <b>Zhiwu Huang</b>, Shuhang Gu, Radu Timofte. The Vid3oC and IntVID Datasets for Video Super Resolution and Quality Mapping. In <em>  International Conference on Computer Vision (ICCV) workshop, 2019 </em>. <a href="http://www.vision.ee.ethz.ch/~timofter/publications/Kim-ICCVW-2019.pdf">Paper</a> | <a href="https://competitions.codalab.org/competitions/20247">Video Mapping Data</a> | <a href="https://competitions.codalab.org/competitions/24685">Video SR Data</a> -->
      
      <p> Jiqing Wu*, <b>Zhiwu Huang*</b>, Dinesh Acharya, Wen Li, Janine Thoma, Danda Pani Paudel,  Luc Van Gool. <em> (*indicates equal contributions) </em>. Sliced Wasserstein Generative Models. In <em> Computer Vision and Pattern Recognition (CVPR), 2019 </em>. <a href="https://arxiv.org/pdf/1706.02631.pdf">Paper</a> | <a href="./Papers/SWGM_supp_CVPR2019.pdf">Supp</a> | <a href="https://github.com/musikisomorphie/swd">Code</a> <br> <!--<b> (Automated Data Learning for Deepfake Computing) </b>-->
	  <b> Extension:</b> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs. <em>  <a href="https://arxiv.org/abs/1810.02419"> arXiv preprint arXiv:1810.02419 </a>, 2018. </em> 

      </p>

      <!-- <p> <b>Zhiwu Huang</b>, Jiqing Wu, Luc Van Gool. Manifold-valued Image Generation with Wasserstein Generative Adversarial Nets. In <em> Association for the Advancement of Artificial Intelligence (AAAI),  2019 </em>. <a href="https://arxiv.org/pdf/1712.01551.pdf">Paper</a> | <a href="https://data.vision.ee.ethz.ch/zzhiwu/manifoldwgan_aaai19_master.zip"> Code (raw)</a> | <a href="https://data.vision.ee.ethz.ch/zzhiwu/manifoldwgan_data1.zip"> Data1 (raw)</a> | <a href="https://data.vision.ee.ethz.ch/zzhiwu/manifoldwgan_data2.zip"> Data2 (raw)</a> -->

      <!-- <h2>2018</h2>-->

      <p> Jiqing Wu, <b>Zhiwu Huang</b>, Janine Thoma, Dinesh Acharya, Luc Van Gool. Wasserstein Divergence for GANs. In <em> European Conference on Computer Vision (ECCV), 2018 </em>. <a href="https://arxiv.org/pdf/1712.01026.pdf">Paper</a> | <a href="https://github.com/musikisomorphie/wgan-div">Code</a>  <!--<b> (Automated Data Learning for Deepfake Computing) </b>-->
	     
      <!--<p> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Covariance Pooling for Facial Expression Recognition. In <em> Computer Vision and Pattern Recognition (CVPR) workshop, 2018 </em>. <a href="https://arxiv.org/pdf/1805.04855.pdf">Paper</a> | <a href="https://github.com/d-acharya/CovPoolFER">Code</a>  <b> (Automated Feature Learning for Affective Computing) </b> -->

      <p> <b>Zhiwu Huang</b>, Jiqing Wu,  Luc Van Gool. Building Deep Networks on Grassmann Manifolds. In <em> Association for the Advancement of Artificial Intelligence (AAAI), 2018 </em>. <a href="https://arxiv.org/pdf/1611.05742.pdf">Paper</a> | <a href="https://github.com/zzhiwu/GrNet">Code</a> <!--<b> (Automated Feature Learning for Affective and Behavioral Computing) </b> -->

      <!-- <p> <b>Zhiwu Huang</b>, Ruiping Wang, Shiguang Shan, Luc Van Gool, Xilin Chen. Cross Euclidean-to-Riemannian Metric Learning with Application to Face Recognition from Video. <em>  IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2018 </em>. <a href="http://arxiv.org/pdf/1608.04200.pdf">Paper</a>
	      
      <p> Wen Wang, Ruiping Wang, <b>Zhiwu Huang</b>, Shiguang Shan, Xilin Chen. Discriminant Analysis on Riemannian Manifold of Gaussian Distributions for Face Recognition with Image Sets. <em>  IEEE Transactions on Image Processing (TIP), 2018 </em>. <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022922">Paper</a> -->
   
      <!-- <h2>2017</h2>-->
      
      <p> <b>Zhiwu Huang</b>, Chengde Wan, Thomas Probst, Luc Van Gool. Deep Learning on Lie Groups for Skeleton-based Action Recognition. In <em> Computer Vision and Pattern Recognition (CVPR), 2017. (Spotlight) </em>. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Deep_Learning_on_CVPR_2017_paper.pdf">Paper</a> | <a href="https://github.com/zzhiwu/LieNet">Code</a> <!-- <b> (Automated Feature Learning for Behavioral Computing) </b>-->

      <p> <b>Zhiwu Huang</b> and Luc Van Gool. A Riemannian Network for SPD Matrix Learning. In <em> Association for the Advancement of Artificial Intelligence (AAAI), 2017 </em>. <a href="https://arxiv.org/pdf/1608.04233.pdf">Paper</a> | <a href="https://github.com/zzhiwu/SPDNet-master">Code</a> </br>  <!--<b> (Automated Feature Learning for Affective and Behavioral Computing) </b>-->
	  <b> Extension:</b> Dinesh Acharya, <b>Zhiwu Huang</b>, Danda Pani Paudel, Luc Van Gool. Covariance Pooling for Facial Expression Recognition. In <em> Computer Vision and Pattern Recognition (CVPR) workshop, 2018 </em>. <a href="https://arxiv.org/pdf/1805.04855.pdf">Paper</a> | <a href="https://github.com/d-acharya/CovPoolFER">Code</a>  

      </p>

      <!--<p> <b>Zhiwu Huang</b>, Ruiping Wang, Xianqiu Li, Wenxian Liu, Shiguang Shan, Luc Van Gool, Xilin Chen. Geometry-aware Similarity Learning on SPD Manifolds for Visual Recognition. <em> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2017</em>. <a href="http://arxiv.org/pdf/1608.04914.pdf"> Paper </a> -->

      <!--<h2> Before 2017 </h2> 
	    
      <p><b>Can be found on <a href="https://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en" target="new">Google Scholar</a></b></p>-->
      
      <h2> <a href="https://scholar.google.ch/citations?user=yh6t92AAAAAJ&hl=en" target="new"> Full Publication </a> </h2>



     
</body>

</html>
